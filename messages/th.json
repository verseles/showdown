{
	"$schema": "https://inlang.com/schema/inlang-message-format",
	"site_title": "Showdown - การจัดอันดับและเปรียบเทียบ LLM อย่างครอบคลุม",
	"site_description": "เปรียบเทียบโมเดลภาษา AI ที่ดีที่สุดในการเขียนโค้ด การให้เหตุผล เอเจนต์ และอื่นๆ การจัดอันดับที่โปร่งใสจาก 20+ เบนช์มาร์ก",
	"og_title": "Showdown - การจัดอันดับ LLM",
	"og_description": "การเปรียบเทียบโมเดล AI อย่างโปร่งใสที่รวบรวม SWE-Bench, GPQA, LMArena และอื่นๆ",
	"header_title": "Showdown",
	"header_tagline": "การจัดอันดับ LLM",
	"header_showing": "แสดง {count} จาก {total} โมเดล",
	"header_updated": "อัปเดต: {date}",
	"aria_select_language": "เลือกภาษา",
	"aria_star_github": "ให้ดาวบน GitHub",
	"aria_switch_light": "สลับไปโหมดสว่าง",
	"aria_switch_dark": "สลับไปโหมดมืด",
	"aria_switch_system": "เปลี่ยนเป็นโหมดระบบ",
	"aria_favorite": "รายการโปรด",
	"aria_add_favorite": "เพิ่มในรายการโปรด",
	"aria_remove_favorite": "ลบออกจากรายการโปรด",
	"aria_show_less": "แสดงน้อยลง",
	"aria_show_more": "แสดงเพิ่มเติม",
	"filter_provider": "ผู้ให้บริการ",
	"filter_provider_placeholder": "[TRANSLATE] Select providers",
	"filter_type": "ประเภท",
	"filter_proprietary": "เชิงพาณิชย์",
	"filter_opensource": "โอเพ่นซอร์ส",
	"filter_favorites_only": "เฉพาะรายการโปรด",
	"filter_reset": "รีเซ็ต",
	"filter_columns": "คอลัมน์",
	"filter_visible_columns": "คอลัมน์ที่มองเห็น",
	"column_rank": "อันดับ",
	"column_rank_score": "อันดับและคะแนน",
	"column_provider": "ผู้ให้บริการ",
	"column_model": "โมเดล",
	"column_type": "ประเภท",
	"column_price": "ราคา",
	"column_speed": "ความเร็ว",
	"column_latency": "ความหน่วง",
	"column_released": "เปิดตัว",
	"column_release_date": "วันที่เปิดตัว",
	"type_proprietary": "เชิงพาณิชย์",
	"type_opensource": "โอเพ่นซอร์ส",
	"type_open": "เปิด",
	"category_coding": "การเขียนโค้ด",
	"category_reasoning": "การให้เหตุผล",
	"category_agents": "เอเจนต์และเครื่องมือ",
	"category_conversation": "การสนทนา",
	"category_math": "คณิตศาสตร์",
	"category_multimodal": "มัลติโมดัล",
	"tooltip_weight": "น้ำหนัก: {percentage}%",
	"tooltip_benchmarks_available": "{available}/{total} เบนช์มาร์กที่มี",
	"tooltip_pricing": "ราคา: {model}",
	"tooltip_input": "อินพุต",
	"tooltip_output": "เอาต์พุต",
	"tooltip_average": "เฉลี่ย",
	"tooltip_per_1m_tokens": "/ 1M โทเค็น",
	"tooltip_average_formula": "เฉลี่ย = (อินพุต + เอาต์พุต) / 2",
	"card_price_avg": "ราคา (เฉลี่ย)",
	"card_input": "อินพุต",
	"card_output": "เอาต์พุต",
	"card_speed": "ความเร็ว",
	"card_latency": "ความหน่วง",
	"card_released": "เปิดตัว",
	"card_show_less": "แสดงน้อยลง",
	"card_show_all": "แสดงทั้งหมด",
	"footer_data_sourced": "ข้อมูลจากเบนช์มาร์กสาธารณะ",
	"footer_contribute": "มีส่วนร่วมบน GitHub",
	"github_star": "Star",
	"aria_toggle_sort_order": "[TRANSLATE] Toggle sort order",
	"filter_search_placeholder": "[TRANSLATE] Search models...",
	"sort_by": "[TRANSLATE] Sort by",
	"category_knowledge": "ความรู้",
	"bench_swe": "SWE-Bench ตรวจสอบแล้ว",
	"bench_terminal": "Terminal-Bench",
	"bench_lmarena_coding": "LMArena การเขียนโค้ด",
	"bench_live_code": "LiveCodeBench",
	"bench_gpqa": "GPQA เพชร",
	"bench_arc": "ARC-AGI-2",
	"bench_livebench": "LiveBench",
	"bench_hle": "การสอบครั้งสุดท้ายของมนุษยชาติ",
	"bench_lmarena_hard": "LMArena ยาก",
	"bench_bfcl": "BFCL",
	"bench_tau": "TAU-Bench",
	"bench_osworld": "OSWorld",
	"bench_webdev": "WebDev Arena",
	"bench_lmarena_creative": "LMArena สร้างสรรค์",
	"bench_lmarena_if": "LMArena IF",
	"bench_math500": "MATH-500",
	"bench_aime": "AIME",
	"bench_lmarena_math": "LMArena คณิตศาสตร์",
	"bench_frontier": "FrontierMath",
	"bench_mathvista": "MathVista",
	"bench_mmmu": "MMMU",
	"bench_mmmu_pro": "MMMU-Pro",
	"bench_lmarena_vision": "LMArena วิสัยทัศน์",
	"bench_mmlu_pro": "MMLU-Pro",
	"bench_mmmlu": "MMMLU",
	"bench_lmarena_en": "LMArena ภาษาอังกฤษ",
	"bench_lmarena_zh": "LMArena ภาษาจีน",
	"category_description_coding": "Measures ability to write, edit, and debug code across multiple programming languages.",
	"category_description_reasoning": "Complex problem-solving and PhD-level questions in science, mathematics, and logical reasoning.",
	"category_description_agents": "Function calling, computer use, and tool integration capabilities for autonomous operation.",
	"category_description_conversation": "Creative writing, instruction following, and conversational quality.",
	"category_description_math": "Mathematical problem solving from elementary to competition level.",
	"category_description_multimodal": "Vision and text understanding, including charts, diagrams, and images.",
	"category_description_knowledge": "Knowledge assessment across subjects and languages.",
	"bench_description_swe_bench": "Real-world GitHub issue resolution from popular Python repositories",
	"bench_description_terminal_bench": "Terminal and command-line task completion",
	"bench_description_lmarena_coding_elo": "Human preference votes on coding tasks",
	"bench_description_live_code_bench": "Competitive programming problems from recent contests",
	"bench_description_aider_polyglot": "Multilingual coding benchmark testing code generation and editing",
	"bench_description_gpqa_diamond": "Graduate-level physics, chemistry, and biology questions",
	"bench_description_arc_agi_2": "ARC-AGI-2: Abstract reasoning and generalization test",
	"bench_description_livebench": "Continuously updated benchmark resistant to contamination",
	"bench_description_humanity_last_exam": "Humanity's Last Exam: PhD-level questions across 100+ domains",
	"bench_description_lmarena_hard_elo": "Human preference on challenging reasoning tasks",
	"bench_description_bfcl": "Function calling accuracy across multiple languages",
	"bench_description_tau_bench": "Collaborative AI agent evaluation",
	"bench_description_osworld": "Computer control and GUI interaction tasks",
	"bench_description_webdev_arena_elo": "Web development task completion",
	"bench_description_lmarena_creative_elo": "Human preference on creative writing tasks",
	"bench_description_lmarena_if_elo": "Human preference on instruction following",
	"bench_description_math_500": "Competition mathematics problems",
	"bench_description_aime": "American Invitational Mathematics Examination",
	"bench_description_lmarena_math_elo": "Human preference on math tasks",
	"bench_description_frontiermath": "Research-level mathematics problems",
	"bench_description_mathvista": "Math reasoning with visual context",
	"bench_description_mmmu": "Massive multi-discipline multimodal understanding",
	"bench_description_mmmu_pro": "Enhanced MMMU evaluation",
	"bench_description_lmarena_vision_elo": "Human preference on vision tasks",
	"bench_description_mmlu_pro": "Enhanced MMLU with reasoning focus",
	"bench_description_mmmlu": "Multilingual MMLU across 14 languages",
	"bench_description_lmarena_en_elo": "Human preference on English tasks",
	"bench_description_lmarena_zh_elo": "Human preference on Chinese tasks",
	"imputed_indicator_title": "มีค่าประมาณการ",
	"imputed_notice": "* = ค่าประมาณการ (คำนวณจากเกณฑ์มาตรฐานอื่นๆ ในหมวดนี้)",
	"superior_imputed_notice": "* = Estimado como superior al modelo base (verde)",
	"confidence_low": "Baja",
	"confidence_medium": "Media",
	"confidence_high": "Alta",
	"bench_livebench_reasoning": "LiveBench Reasoning",
	"bench_livebench_coding": "LiveBench Coding",
	"bench_livebench_agentic_coding": "LiveBench Agentic Coding",
	"bench_livebench_math": "LiveBench Math",
	"bench_livebench_data_analysis": "LiveBench Data Analysis",
	"bench_livebench_language": "LiveBench Language",
	"bench_livebench_if": "LiveBench IF",
	"filter_date_range": "[TRANSLATE] Release Date",
	"filter_date_all": "[TRANSLATE] All time",
	"filter_date_30d": "[TRANSLATE] Last 30 days",
	"filter_date_90d": "[TRANSLATE] Last 90 days",
	"filter_date_180d": "[TRANSLATE] Last 6 months"
}
